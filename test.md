- 합성곱 신경망(CNN, Convolutional Neural Network) -> 이미지, 비전 분야에서 주로 사용
- CNN = 합성곱층(convolution layer) + 풀링층(pooling layer)으로 구성.

![f122caad2dafa25f325735d914867c91.png](:/720f8647489e40b08fbaabef3ade4ed5) 
1) CONV = convollution layer
2) 합성곱 연산의 결과가 활성화 함수 ReLU를 지난다 

 

 

# 1. 합성공 신경망의 대두

- 이미지 처리를 위해 '다층 퍼셉트론'을' 사용할 수 있지만 한계 있음.
![2129dc0c5def31cf58ddc59e81eee7ce.png](:/1710ae3e31b44b6699fd1a64f5001153)

- 다층 퍼셉으론은 몇 가지 픽셀만 값이 달라져도, '민감하게 예측에 영향을 받는다'는 단점.

- 다층 퍼셉트론으로 위 손글씨 분류 : **1차원 텐서인 벡터로 변환 (다층 퍼셉트론 입력층으로 사용)**
![d9f74160c314b178fac45ad2b305633d.png](:/1350116d7913456f8d053784be4428ff)

- 1차원으로 나타내면, 사람도 알기 어려운데, 기계도 마찬가지.

- *변환 전의* ***공간적 구조(spatial structure) 정보****가 유실된 상태.*

> ***CNN : 공간적 구조 정보를 보존하면서 학습.***

 

# 2. 채널(Channel)

- 기계 : 글자, 이미지 <<<< 숫자(텐서)

- **이미지(3차원 텐서) = (높이, 너비, 채널=깊이)**

- ***채널(=깊이depth) : 색 성분 (흑백 채널 수=1, 컬러 채널 수=3)***

 

# 3. 합성곱 연산(Convolution Operation)


- 합성곱층 : 합성곱 연산을 통해서 **이미지의 특징을 추출**하는 역할.

- **커널(kernel)=필터(filter) : n x m 크기의 행렬** (주로 3x3, 5x5)

- 커널을 이미지의 왼쪽 위부터 겹쳐 훑으며, 각 원소의 곱을 모두 더한다.

![7315ed77769557c84863f2e0ca8cf7a1.png](:/aedf6161bb12410d9c10202ab8a8bf6e)

(9번의 step까지 마치면,)
![fe54e4cac5377869c351f053eb72d5a8.png](:/045952834230477fae6f51f9e23b7216)
- ***특성 맵(feature map)*** : 입력으로부터 거널을 사용하여 합성곱 연산을 통해 나온 결과. / 입력보다 크기 작아짐.

- ***스트라이드(stride)*** : 커널이 한번에 이동하는 범위.

(스트라이드=2일 경우,)
![e88c4e98513123fb549918975a1a894e.png](:/764b34d26f3644fea4bbdf2baa0ca331)
 

 

# 4. 패딩(Padding)

- 합성곱 연산 결과 : 특성 맵은 입력보다 크기가 작음.

- 합성곱 '여러 개' 결과 : 최종 특성 맵은 초기 입력보다 매우 작음.

- 원하는 것 : (입력 크기)=(특성 맵 크기)

- 해결 : 패딩(padding)

---

- 패딩 : 합성곱 연산 이전에, 입력의 가장자리에 행과 열을 추가해주는 것. (테두리 추가.)

- 제로 패딩(zero padding) : 0으로 채움. 주로 사용.

 

**[ 예시 : 경우에 따른 패딩 방법 ]**

- 3x3 커널 사용 : 1폭짜리 zero padding. -> 특성 맵 3x3

- 5x5 커널 사용 : 2폭짜리 zero padding. -> 특성 맵 5x5

 

# 5. W와 b(가중치와 편향)
with 다층 퍼셉트론 복습(비교)
## 1) 합성곱 신경망의 가중치
**[ 예시 상황 - 1) 다중 퍼셉트론으로 해결 ]**
![e316bbbedb78901b79303251f637a029.png](:/ad148b6f5a224f66ad3e31fa8d542093)

**[ 예시 상황 - 2) 합성곱 신경망으로 해결 ]**
![eaa439a2ce40b953544b15513a4e0aba.png](:/cdc7d9fa8e204e249d37db36fadcfadc)

**[ 참고 : CNN에서 W는 커널 행렬의 원소들 ]**
![10cef91264499823ea5b51ca707ad974.png](:/bfaea76306a547329e7c4511970bfa30)
- 이미지 전체를 훑으면서 사용되는 가중치 : w0, w1, w2, w3 4개 뿐.
- 각 합성곱 연산마다 이미지의 모든 픽셀을 사용하는 것이 아님. (커널과 '맵핑'되는 픽셀만 입력으로 사용.)
- ***CNN : 다층 퍼셉트론을 사용할 때, 보다 훨씬 '적은 수의 가중치를 사용'하며, '공간적 구조 정보를 보존'한다는 특징이 있다.***

## 2) 합성곱 신경망의 편향
![f3404ea4fbec1613df5dc6fff0b41bf8.png](:/72ce217fb73b4958a423661c282e39b0)
- CNN에서 편향 사용 시, **커널을 적용한 뒤에 더해짐.**
- 편향은 하나의 값만 존재. 커널이 적용된 결과의 '모든 원소에 더해짐'.

# 6. 특성 맵의 크기 계산 방법
![67553d3e994df970bc87335c979bb9a3.png](:/b3d3f24174b14c6b9b7e7e8abad8230f)
![012ee843f49fbe7f51309aede39a9643.png](:/a3cd46abd642481fb056436a59b6ccf7)
![fb5214facf960b3dc3f4a7d2b791e11a.png](:/c42a196d3aa24d03acfe74474464c529)

# 7. 다수의 채널을 가질 경우의 합성곱 연산(3차원 텐서의 합성곱 연산)
- 지금까지는 2차원 텐서만 가정했었음. (채널=깊이(개수) 를 고려x)
- 가능한 입력 : **'다수의 채널을 가진' 이미지, 이전 연산의 결과로 나온 특성 맵**
- (입력의 채널 수) = (커널의 채널 수) : 합성곱 연산을 채널마다 수행, 여러개 특성 맵의 원소별 합을 구해서 하나의 특성 맵 계산.

[ 예시 ]
![7eead3da62dcb46d3a08439a7f06ef18.png](:/7f4a884c3cba4d4dbbdbdcd4382f3fda)
***"3개의 커널이 아니라, 3개의 채널을 가진 1개의 커널."***
- 입력 : (높이, 너비, 채널) = (3, 3, 3)
- 커널 : (높이, 너비, 채널) = (2, 2, 3)
- 특성 맵 : (높이, 너비, 채널) = (2, 2, 1)
> 위 연산에서 각 '차원'을 '변수'로 두고, 좀 더 일반화시켜보자.

# 8. 3차원 텐서의 합성곱 연산
![5283cb90f110f51e71c9927d94c2c5f8.png](:/7a281186e6314b0a9b950b95db26c40d)
[ 3차원 텐서의 합성곱 연산 ]
![4172c1b6614f0e331ceb49da65109c73.png](:/267944a5d380496fa30cfdefb1d3a95c)

[ **여러 개의 커널**을 사용하는 합성곱 연산 ]
- 사용한 커널 수는 합성곱 연산의 결과로 나오는 '특성 맵'에서 '채널 수'가 된다.
![8be1cb1f0f4212aef85cd21d11a46e23.png](:/c05bd40d148d4e88b3d844dcf01b14b1)

---
- 하나의 커널이 가지는 매개변수의 수 : ![4364438c2e1e8f328c7761bfcc8b843f.png](:/b3ba53a6d925490e8dde82d2a7a2811e)
- 가중치 매개변수의 총 수 : ![a2abcd957b0c728f0f2ff9f4e8cd51b4.png](:/edfad38f4bec4a76b53c72220ab1d453) (i = input, o = output)

# 9. 풀링(Pooling)
- *합성곱 층(합성곱 연산 + 활성화 함수)*
- *-> 풀링 층 추가.*
- **풀링 층** : 특성 맵을 **'다운샘플링'** 하여, 특성 맵의 크기를 줄이는 풀링 연산이 이루어짐.
- **최대 풀링(max pooling), 평균 풀링(average pooling)**

[ 예시 : 최대 풀링(max pooling) ]
![b73923beff6ad8b82c6ff321d087eaa4.png](:/8046308fbae24649b28584df06538668)
- 풀링 연산에서도, '커널'과 '스트라이드'의 개념을 가짐.
- 위 예시 : 2X2 크기 커널로 **'맥스 풀링 연산'** 을 했을 때, 특성맵이 절반 크기로 '다운샘플링' 됨.

[ 합성곱 연산 VS. 풀링 연산 ]
- 유사 : 커널과 스트라이드 존재
- 차이점(풀링 연산 특징) ; **학습해야 할 W가 없음 + 연산 후에 채널 수가 변하지 않음.** (합성곱 연산에서는 3개채널 예시에서, 특성 맵의 채널이 1로 감소함.)
- 풀링 사용 시, 특성 맵의 **'크기'가 줄어들음** : (이후 계산에 쓰이는) W의 개수 줄어들음.
- (풀링 : 채널 수 - 불변, 특성 맵 크기 - 줄어듦.)
---
### [ 참고 ] 업 샘플링(up sampling) & 다운 샘플링(down sampling)
- **업 샘플링** : 해당 분류에 속하는 데이터가 '적은 쪽을 표본으로 더 많이 추출'하는 방법.
- **다운 샘플링** : 해당 분류에 속하는 데이터가 '많은 쪽을 표본으로 적게 추출'하는 방법








